{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false
      },
      "source": [
        "1D Constrained\n",
        "---\n",
        "\n",
        "In this interactive tutorial we demonstrate basic usage of `optimusprimal` for a 1-dimensional noisy fitting problem."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "How to run a basic 1D constrained proximal primal-dual solver. \n",
        "We consider the canonical problem $y = x + n$ where $n \\sim \\mathcal{N}$. \n",
        "This inverse problem can be solved via the constrained optimisation \n",
        "\n",
        "$$\n",
        "\\min_x [ ||\\Psi^{\\dagger} x||_1 ]  \\quad s.t. \\quad  ||x-y||^2_2 \\leq \\epsilon\n",
        "$$\n",
        "\n",
        "where $x \\in \\mathbb{R}$ is an a priori ground truth 1D signal and $y \\in \\mathbb{R}$ \n",
        "are simulated noisy observations. Before we begin, we need to import ``optimusprimal`` and \n",
        "some example specific packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from scipy.stats import norm as normal_dist\n",
        "\n",
        "import optimusprimal.primal_dual as primal_dual\n",
        "import optimusprimal.linear_operators as linear_operators\n",
        "import optimusprimal.prox_operators as prox_operators"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "First, we need to define some heuristics for the solver, these include:\n",
        "      - tol: convergence criteria for the iterations\n",
        "      - iter: maximum number of iterations\n",
        "      - update_iter: iterations between logging iteration diagnostics\n",
        "      - record_iters: whether to record the full diagnostic information\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "options = {\"tol\": 1e-5, \"iter\": 5000, \"update_iter\": 50, \"record_iters\": False}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Next, we simulate a standard de-noising setting by contaminating a known\n",
        "signal $x$` with some Gaussianly distributed noise. Note that for simplicity the\n",
        "measurement operator here is taken to be the identity operator.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "size = 2048                                              # Dimension of the 1D vector\n",
        "ISNR = 20.0                                              # Input signal to noise ratio\n",
        "sigma = 10 ** (-ISNR / 20.0)                             # Noise standard deviation\n",
        "epsilon = np.sqrt(size + 2.0 * np.sqrt(size)) * sigma    # Radius of l2-ball\n",
        "\n",
        "x = normal_dist(0, 0.5).pdf(np.linspace(-2, 2, size))    # Ground truth signal x\n",
        "y = x + np.random.normal(0, sigma, size)                 # Simulated observations y"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "For the constrained problem with Gaussian noise the data-fidelity constraint\n",
        "is given by a projection onto the $\\ell_2$-ball. Here we set up a linear-operator\n",
        "corresponding to a forward and adjoint projection onto the $\\ell_2$-ball.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "p = prox_operators.l2_ball(epsilon, y, linear_operators.identity())\n",
        "p.beta = 1.0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We regularise this inverse problem by adopting a wavelet sparsity $\\ell_1$-norm prior.\n",
        "To do this we first define what wavelets we wish to use, in this case a\n",
        "combination of Daubechies family wavelets, and which levels to consider.\n",
        "Any combination of wavelet families available by the [`PyWavelet`](https://tinyurl.com/5n7wzpmb) package may be\n",
        "selected.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "wav = [\"db1\", \"db4\", \"db6\"]                               # Wavelet dictionaries to combine\n",
        "levels = 6                                                # Wavelet levels to consider [1-6]\n",
        "shape = (size,)                                           # Shape of nd-wavelets\n",
        "psi = linear_operators.dictionary(wav, levels, shape)     # Wavelet linear operator"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Next we construct the $\\ell_1$-norm proximal operator which we pass the wavelets\n",
        "($\\Psi$) as a dictionary in which to compute the $\\ell_1$-norm. We also add an\n",
        "additional reality constraint f for good measure, as we know a priori our\n",
        "signal $x$ is real.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "h = prox_operators.l1_norm(np.max(np.abs(psi.dir_op(y))) * 1e-2, psi)\n",
        "h.beta = 1.0\n",
        "f = prox_operators.real_prox()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Finally we run the optimisation...\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "best_estimate, diagnostics = primal_dual.FBPD(y, options, None, f, h, p, None)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "...and plot the results!\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def eval_snr(x, x_est):\n",
        "    if np.array_equal(x, x_est):\n",
        "        return 0\n",
        "    num = np.sqrt(np.sum(np.abs(x) ** 2))\n",
        "    den = np.sqrt(np.sum(np.abs(x - x_est) ** 2))\n",
        "    return round(20*np.log10(num/den), 2)\n",
        "\n",
        "SNR_est = eval_snr(x, best_estimate)\n",
        "SNR_data = eval_snr(x, y)\n",
        "\n",
        "plt.plot(np.real(y), \"o\", markersize=1)\n",
        "plt.plot(np.real(x), linewidth=2)\n",
        "plt.plot(np.real(best_estimate), linewidth=2)\n",
        "plt.legend([\"data\", \"true\", \"fit\"])\n",
        "\n",
        "plt.title(\"Data SNR: {}dB, Reconstruction SNR: {}dB\".format(SNR_data, SNR_est), fontsize=16)\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
